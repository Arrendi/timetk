% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune-tk_tune_parameters.R
\name{tk_tune_rank_parameters}
\alias{tk_tune_rank_parameters}
\title{Rank Hyperparameter Tuning Results}
\usage{
tk_tune_rank_parameters(.data, .metric, .max_failure_rate = 1)
}
\arguments{
\item{.data}{A \code{tibble} of class "tune_results"}

\item{.metric}{Select a metric to use for tuning performance investigation.}

\item{.max_failure_rate}{Range (0,1). Use to \code{.max_failure_rate} to filter models below an acceptable failure threshold.}
}
\value{
A \code{tibble} or \code{data.frame} with ranked tuning parameters.
}
\description{
\code{tk_tune_rank_parameters()} returns the tuning performance results
from functions like \code{tune::tune_grid()}. If possible, adds parameter ranking
results based on metric performance, model failure rates, and standard error (variability).
}
\details{
\strong{Metric Ranking (Model Accuracy)}

The model with the lowest (best) rank is that with the lowest mean error.

\strong{Failure Rate Ranking (Robustness to New Data)}

Models with lower failure rates are more robust to new data.
Failure rate rank is a score based on the proportion of models that failed during tuning.
\itemize{
\item Calculation: \emph{Failure Rate = n / No. of Resample Slices}
\item Models with a non-zero failure rate have a higher likelihood of failing on new data
and are therefore less robust.
}

\strong{Standard Error Ranking (Model Variability)}

Models with lower standard error are more consistent (less variability).
}
\examples{
library(dplyr)
library(tune)
library(timetk)

arima_workflow_tuned \%>\%
    tk_tune_rank_parameters(.max_failure_rate = 1)

}
